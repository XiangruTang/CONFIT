# CONFIT: Toward Faithful Dialogue Summarization with Linguistically-Informed Contrastive Fine-tuning

We propose a training strategy that improves the factual consistency and overall quality of summaries via a novel contrastive fine-tuning, called ConFiT. Based on our linguistically-informed typology of errors, we design different modular objectives that each target a specific type.

## Trainig

## Test

## Model

## Annotation


## Citation
```
@article{tang2021confit,
  title={CONFIT: Toward Faithful Dialogue Summarization with Linguistically-Informed Contrastive Fine-tuning},
  author={Tang, Xiangru and Nair, Arjun and Wang, Borui and Wang, Bingyao and Desai, Jai and Wade, Aaron and Li, Haoran and Celikyilmaz, Asli and Mehdad, Yashar and Radev, Dragomir},
  journal={arXiv preprint arXiv:2112.08713},
  year={2021}
}

```
